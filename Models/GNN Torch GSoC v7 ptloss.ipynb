{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eca9762f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import numpy.matlib\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from livelossplot import PlotLossesKerasTF\n",
    "from sklearn.metrics import f1_score, accuracy_score, roc_curve, auc\n",
    "from sklearn.metrics import mean_absolute_error as mae\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "67a88d8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.datasets import Planetoid\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import MessagePassing\n",
    "from torch_geometric.utils import add_self_loops, degree\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3bb6d782",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.data import Dataset, Data, DataLoader\n",
    "import torch_geometric.nn as gnn\n",
    "from torch_geometric.utils import softmax\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import os\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
    "from IPython.display import Javascript"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2a8b6a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "inv = 1\n",
    "# for i in range(2):\n",
    "#     inv = invs[i]\n",
    "#     display(Javascript('IPython.notebook.execute_cells_below()'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "711c1185",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Unnamed: 0', 'Phi_0', 'Phi_2', 'Phi_3', 'Phi_4', 'Theta_0', 'Theta_2',\n",
      "       'Theta_3', 'Theta_4', 'BendingAngle_0', 'BendingAngle_2',\n",
      "       'BendingAngle_3', 'BendingAngle_4', 'TimeInfo_0', 'TimeInfo_2',\n",
      "       'TimeInfo_3', 'TimeInfo_4', 'RingNumber_0', 'RingNumber_2',\n",
      "       'RingNumber_3', 'RingNumber_4', 'Front_0', 'Front_2', 'Front_3',\n",
      "       'Front_4', 'Mask_0', 'Mask_2', 'Mask_3', 'Mask_4',\n",
      "       'PatternStraightness', 'Zone', 'MedianTheta', 'q/pt', 'PhiAngle',\n",
      "       'EtaAngle'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Phi_0</th>\n",
       "      <th>Phi_2</th>\n",
       "      <th>Phi_3</th>\n",
       "      <th>Phi_4</th>\n",
       "      <th>Theta_0</th>\n",
       "      <th>Theta_2</th>\n",
       "      <th>Theta_3</th>\n",
       "      <th>Theta_4</th>\n",
       "      <th>BendingAngle_0</th>\n",
       "      <th>...</th>\n",
       "      <th>Mask_0</th>\n",
       "      <th>Mask_2</th>\n",
       "      <th>Mask_3</th>\n",
       "      <th>Mask_4</th>\n",
       "      <th>PatternStraightness</th>\n",
       "      <th>Zone</th>\n",
       "      <th>MedianTheta</th>\n",
       "      <th>q/pt</th>\n",
       "      <th>PhiAngle</th>\n",
       "      <th>EtaAngle</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>58.066666</td>\n",
       "      <td>55.466667</td>\n",
       "      <td>55.466667</td>\n",
       "      <td>56.000000</td>\n",
       "      <td>11.970</td>\n",
       "      <td>11.684999</td>\n",
       "      <td>11.400</td>\n",
       "      <td>11.400</td>\n",
       "      <td>-13.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>105.0</td>\n",
       "      <td>0.181209</td>\n",
       "      <td>-3.075936</td>\n",
       "      <td>1.722345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>64.583336</td>\n",
       "      <td>66.800000</td>\n",
       "      <td>67.066666</td>\n",
       "      <td>67.200000</td>\n",
       "      <td>6.555</td>\n",
       "      <td>6.840000</td>\n",
       "      <td>6.555</td>\n",
       "      <td>6.840</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>124.0</td>\n",
       "      <td>-0.146131</td>\n",
       "      <td>-0.167139</td>\n",
       "      <td>2.012122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>71.150000</td>\n",
       "      <td>67.033330</td>\n",
       "      <td>66.266670</td>\n",
       "      <td>65.466670</td>\n",
       "      <td>2.850</td>\n",
       "      <td>2.565000</td>\n",
       "      <td>2.280</td>\n",
       "      <td>2.280</td>\n",
       "      <td>-16.613783</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>127.0</td>\n",
       "      <td>0.367024</td>\n",
       "      <td>2.431823</td>\n",
       "      <td>2.321646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>34.933334</td>\n",
       "      <td>31.200000</td>\n",
       "      <td>31.200000</td>\n",
       "      <td>31.833334</td>\n",
       "      <td>9.690</td>\n",
       "      <td>8.835000</td>\n",
       "      <td>8.835</td>\n",
       "      <td>9.120</td>\n",
       "      <td>-13.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.267774</td>\n",
       "      <td>-1.343305</td>\n",
       "      <td>1.854506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>68.150000</td>\n",
       "      <td>68.266670</td>\n",
       "      <td>68.300000</td>\n",
       "      <td>68.400000</td>\n",
       "      <td>2.565</td>\n",
       "      <td>2.565000</td>\n",
       "      <td>2.565</td>\n",
       "      <td>2.565</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>-0.019179</td>\n",
       "      <td>-3.134433</td>\n",
       "      <td>2.333772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1179351</th>\n",
       "      <td>1179351</td>\n",
       "      <td>30.450000</td>\n",
       "      <td>29.066668</td>\n",
       "      <td>28.933332</td>\n",
       "      <td>28.933332</td>\n",
       "      <td>9.405</td>\n",
       "      <td>9.120000</td>\n",
       "      <td>9.120</td>\n",
       "      <td>9.120</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>0.118520</td>\n",
       "      <td>0.522333</td>\n",
       "      <td>-1.833125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1179352</th>\n",
       "      <td>1179352</td>\n",
       "      <td>39.400000</td>\n",
       "      <td>40.133335</td>\n",
       "      <td>40.266666</td>\n",
       "      <td>40.400000</td>\n",
       "      <td>3.705</td>\n",
       "      <td>3.420000</td>\n",
       "      <td>3.420</td>\n",
       "      <td>3.420</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>-0.084559</td>\n",
       "      <td>-1.585937</td>\n",
       "      <td>-2.262504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1179353</th>\n",
       "      <td>1179353</td>\n",
       "      <td>65.533330</td>\n",
       "      <td>63.433334</td>\n",
       "      <td>62.933334</td>\n",
       "      <td>63.066666</td>\n",
       "      <td>7.125</td>\n",
       "      <td>6.555000</td>\n",
       "      <td>6.555</td>\n",
       "      <td>6.555</td>\n",
       "      <td>-9.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>0.173085</td>\n",
       "      <td>1.175915</td>\n",
       "      <td>-1.988468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1179354</th>\n",
       "      <td>1179354</td>\n",
       "      <td>41.283333</td>\n",
       "      <td>40.533333</td>\n",
       "      <td>40.366665</td>\n",
       "      <td>40.400000</td>\n",
       "      <td>3.990</td>\n",
       "      <td>3.705000</td>\n",
       "      <td>3.705</td>\n",
       "      <td>3.705</td>\n",
       "      <td>-5.537928</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>0.085662</td>\n",
       "      <td>2.748315</td>\n",
       "      <td>-2.236174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1179355</th>\n",
       "      <td>1179355</td>\n",
       "      <td>72.133330</td>\n",
       "      <td>70.533330</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>69.600000</td>\n",
       "      <td>2.850</td>\n",
       "      <td>2.565000</td>\n",
       "      <td>2.565</td>\n",
       "      <td>2.565</td>\n",
       "      <td>-9.229879</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>133.0</td>\n",
       "      <td>0.189065</td>\n",
       "      <td>-1.878648</td>\n",
       "      <td>-2.330181</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1179356 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Unnamed: 0      Phi_0      Phi_2      Phi_3      Phi_4  Theta_0  \\\n",
       "0                 0  58.066666  55.466667  55.466667  56.000000   11.970   \n",
       "1                 1  64.583336  66.800000  67.066666  67.200000    6.555   \n",
       "2                 2  71.150000  67.033330  66.266670  65.466670    2.850   \n",
       "3                 3  34.933334  31.200000  31.200000  31.833334    9.690   \n",
       "4                 4  68.150000  68.266670  68.300000  68.400000    2.565   \n",
       "...             ...        ...        ...        ...        ...      ...   \n",
       "1179351     1179351  30.450000  29.066668  28.933332  28.933332    9.405   \n",
       "1179352     1179352  39.400000  40.133335  40.266666  40.400000    3.705   \n",
       "1179353     1179353  65.533330  63.433334  62.933334  63.066666    7.125   \n",
       "1179354     1179354  41.283333  40.533333  40.366665  40.400000    3.990   \n",
       "1179355     1179355  72.133330  70.533330  70.000000  69.600000    2.850   \n",
       "\n",
       "           Theta_2  Theta_3  Theta_4  BendingAngle_0  ...  Mask_0  Mask_2  \\\n",
       "0        11.684999   11.400   11.400      -13.000000  ...     0.0     0.0   \n",
       "1         6.840000    6.555    6.840        7.000000  ...     0.0     0.0   \n",
       "2         2.565000    2.280    2.280      -16.613783  ...     0.0     0.0   \n",
       "3         8.835000    8.835    9.120      -13.000000  ...     0.0     0.0   \n",
       "4         2.565000    2.565    2.565        0.000000  ...     0.0     0.0   \n",
       "...            ...      ...      ...             ...  ...     ...     ...   \n",
       "1179351   9.120000    9.120    9.120        0.000000  ...     0.0     0.0   \n",
       "1179352   3.420000    3.420    3.420       -0.000000  ...     0.0     0.0   \n",
       "1179353   6.555000    6.555    6.555       -9.000000  ...     0.0     0.0   \n",
       "1179354   3.705000    3.705    3.705       -5.537928  ...     0.0     0.0   \n",
       "1179355   2.565000    2.565    2.565       -9.229879  ...     0.0     0.0   \n",
       "\n",
       "         Mask_3  Mask_4  PatternStraightness  Zone  MedianTheta      q/pt  \\\n",
       "0           0.0     0.0                  5.0   3.0        105.0  0.181209   \n",
       "1           0.0     0.0                  3.0   1.0        124.0 -0.146131   \n",
       "2           0.0     0.0                  7.0   0.0        127.0  0.367024   \n",
       "3           0.0     0.0                  6.0   2.0         60.0  0.267774   \n",
       "4           0.0     0.0                  4.0   0.0        128.0 -0.019179   \n",
       "...         ...     ...                  ...   ...          ...       ...   \n",
       "1179351     0.0     0.0                  5.0   2.0         55.0  0.118520   \n",
       "1179352     0.0     0.0                  4.0   0.0         75.0 -0.084559   \n",
       "1179353     0.0     0.0                  5.0   1.0        120.0  0.173085   \n",
       "1179354     0.0     0.0                  4.0   0.0         77.0  0.085662   \n",
       "1179355     0.0     0.0                  5.0   0.0        133.0  0.189065   \n",
       "\n",
       "         PhiAngle  EtaAngle  \n",
       "0       -3.075936  1.722345  \n",
       "1       -0.167139  2.012122  \n",
       "2        2.431823  2.321646  \n",
       "3       -1.343305  1.854506  \n",
       "4       -3.134433  2.333772  \n",
       "...           ...       ...  \n",
       "1179351  0.522333 -1.833125  \n",
       "1179352 -1.585937 -2.262504  \n",
       "1179353  1.175915 -1.988468  \n",
       "1179354  2.748315 -2.236174  \n",
       "1179355 -1.878648 -2.330181  \n",
       "\n",
       "[1179356 rows x 35 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('input/CMS_trigger.csv')\n",
    "print(df.columns)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4480e60d",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler_1 = StandardScaler()\n",
    "df.loc[:,'Phi_0':'MedianTheta'] = scaler_1.fit_transform(df.loc[:,'Phi_0':'MedianTheta']) # normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "acee0c4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['Phi_'+str(i) for i in [0,2,3,4]] + ['Theta_'+str(i) for i in [0,2,3,4]] + \\\n",
    "['Front_'+str(i) for i in [0,2,3,4]] + ['BendingAngle_'+str(i) for i in [0,2,3,4]] + \\\n",
    "['RingNumber_'+str(i) for i in [0,2,3,4]]\n",
    "# ['TimeInfo_'+str(i) for i in [0,2,3,4]] + ['Mask_'+str(i) for i in [0,2,3,4]] #+ ['PatternStraightness'] + ['Zone'] + ['MedianTheta']\n",
    "# edge_index = torch.tensor([(0,1),(1,2),(2,3),(3,2),(2,1),(1,0)], dtype=torch.long).T\n",
    "edge_index = [(0,1),(1,2),(2,3),(3,2),(2,1),(1,0)]\n",
    "# edge_index = [(0,1),(1,2),(2,3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4d73a1e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape: (1179356, 20)\n",
      "(1179356,)\n",
      "Len train: 943484, Len test: 235872\n",
      "Num. features: 20\n"
     ]
    }
   ],
   "source": [
    "# x_train, x_test, pT_tr, pT_ts, inv_pT_tr, inv_pT_ts = train_test_split(df[features].to_numpy(), abs(1/df.loc[:,'q/pt']).to_numpy(), 1/abs(1/df.loc[:,'q/pt']).to_numpy(), test_size = 0.2, random_state = 1)\n",
    "train_mask, test_mask = train_test_split(df['Unnamed: 0'].to_numpy(), test_size = 0.2, random_state = 1)\n",
    "x_data = df[features].to_numpy()\n",
    "pT = abs(1/df.loc[:,'q/pt']).to_numpy()\n",
    "inv_pT = 1/pT\n",
    "if inv:\n",
    "    label = inv_pT\n",
    "else:\n",
    "    label = pT\n",
    "num_features = x_data.shape[-1]\n",
    "print('Data shape: ' + str(x_data.shape))\n",
    "print(pT.shape)\n",
    "print('Len train: '+str(len(train_mask))+', Len test: '+str(len(test_mask)))\n",
    "print('Num. features: '+str(num_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "060e0769",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data(i):\n",
    "    \n",
    "    data = Data(x=torch.tensor(x_data[i].reshape(-1,4).T, dtype=torch.float), y=torch.tensor(label[i], dtype=torch.float),\n",
    "                edge_index=torch.tensor(edge_index, dtype = torch.long).T)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6d852c1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MPL(MessagePassing):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(MPL, self).__init__(aggr='add')\n",
    "        self.mlp1 = torch.nn.Linear(in_channels*2, out_channels)\n",
    "        self.mlp2 = torch.nn.Linear(in_channels, out_channels)\n",
    "        self.mlp3 = torch.nn.Linear(2*out_channels, 1)\n",
    "        self.mlp4 = torch.nn.Linear(2*out_channels, 1)\n",
    "        self.mlp5 = torch.nn.Linear(in_channels,16)\n",
    "        self.mlp6 = torch.nn.Linear(out_channels,16)\n",
    "        self.mlp7 = torch.nn.Linear(16,1)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "#         edge_index, _ = add_self_loops(edge_index, num_nodes=x.size(0))\n",
    "        msg = self.propagate(edge_index, x=x)\n",
    "        x = F.relu(self.mlp2(x))\n",
    "        w1 = F.sigmoid(self.mlp3(torch.cat([x,msg], dim=1)))\n",
    "        w2 = F.sigmoid(self.mlp4(torch.cat([x,msg], dim=1)))\n",
    "        out = w1*msg + w2*x\n",
    "        \n",
    "        return out\n",
    "\n",
    "    def message(self, x_i, x_j, edge_index):\n",
    "        msg = F.relu(self.mlp1(torch.cat([x_i, x_j-x_i], dim=1)))\n",
    "        w1 = F.tanh(self.mlp5(x_i))\n",
    "        w2 = F.tanh(self.mlp6(msg))\n",
    "        w = self.mlp7(w1*w2)\n",
    "        w = softmax(w, edge_index[0])\n",
    "        return msg*w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "748dc2ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MPNN(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MPNN, self).__init__()\n",
    "        self.conv1 = MPL(int(len(features)/4),128 )\n",
    "        self.conv2 = MPL(128,64)\n",
    "        self.conv3 = MPL(64,64 )\n",
    "        self.conv4 = MPL(64,64 )\n",
    "        self.lin1 = torch.nn.Linear(128, 128)\n",
    "        self.lin2 = torch.nn.Linear(128, 16)\n",
    "        self.lin3 = torch.nn.Linear(16, 16)\n",
    "        self.lin4 = torch.nn.Linear(16, 1)\n",
    "        self.lin5 = torch.nn.Linear(128, 128)\n",
    "        self.lin6 = torch.nn.Linear(128, 16)\n",
    "        self.lin7 = torch.nn.Linear(16, 16)\n",
    "        self.lin8 = torch.nn.Linear(16, 1)\n",
    "        self.global_att_pool1 = gnn.GlobalAttention(torch.nn.Sequential(torch.nn.Linear(64, 1)))\n",
    "        self.global_att_pool2 = gnn.GlobalAttention(torch.nn.Sequential(torch.nn.Linear(64, 1)))\n",
    "    \n",
    "    def forward(self, data):\n",
    "        x, edge_index, batch = data.x, data.edge_index, data.batch\n",
    "        x = F.relu(self.conv1(x, edge_index))\n",
    "        x = F.relu(self.conv2(x, edge_index))\n",
    "        x1 = self.global_att_pool1(x, batch)\n",
    "        x = F.relu(self.conv3(x, edge_index))\n",
    "        x = F.relu(self.conv4(x, edge_index))\n",
    "        x2 = self.global_att_pool2(x, batch)\n",
    "        x_out = torch.cat([x1, x2], dim=1)\n",
    "        x = F.relu(self.lin1(x_out))\n",
    "        x = F.relu(self.lin2(x))\n",
    "        x = self.lin3(x)\n",
    "        x = self.lin4(x).squeeze(1)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f91d9fb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "    def __init__(self, indices=list(range(len(df))), transform=None):\n",
    "        self.transform = transform\n",
    "        self.indices = indices\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return process_data(self.indices[idx])\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "91a249e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pTLossTorch(y_pred,y_true):\n",
    "#     if not inv:\n",
    "#         y_pred = torch.pow(y_pred,-1)\n",
    "#         y_true = torch.pow(y_true,-1)\n",
    "    y_t = (y_true<80).type(torch.FloatTensor)*y_true.type(torch.FloatTensor) + (y_true>=80).type(torch.FloatTensor)*(y_true<250).type(torch.FloatTensor)*y_true.type(torch.FloatTensor)**2.4 + (y_true>=160).type(torch.FloatTensor)*10 \n",
    "    return torch.mean(y_t.type(torch.FloatTensor)*torch.pow((y_pred-y_true)/y_true,2).type(torch.FloatTensor))/250"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8444907d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(prog_bar = True):\n",
    "    \n",
    "    train_losses, test_losses = list(), list()\n",
    "    min_test_loss = float('inf')\n",
    "    train_loader = DataLoader(MyDataset(indices=train_mask), batch_size=batch_size)\n",
    "    test_loader = DataLoader(MyDataset(indices=test_mask), batch_size=batch_size)\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        train_loss = 0\n",
    "        test_loss = 0\n",
    "        if prog_bar:\n",
    "            pbar = tqdm(train_loader,position=0)\n",
    "        else:\n",
    "            pbar = train_loader\n",
    "            \n",
    "        # train\n",
    "        for data in pbar:\n",
    "            data = data.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            out = model(data)\n",
    "            labels = data.y\n",
    "            loss = pTLossTorch(out, data.y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            if prog_bar:\n",
    "                pbar.set_description('pTLoss: '+str(loss.cpu().detach().numpy()))\n",
    "                train_loss += loss.cpu().detach().numpy()/len(train_loader)\n",
    "                \n",
    "        # test\n",
    "        for data in test_loader:\n",
    "            data = data.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            out = model(data)\n",
    "            labels = data.y\n",
    "            loss = pTLossTorch(out, data.y)\n",
    "            test_loss += loss.cpu().detach().numpy()/len(test_loader)\n",
    "        if test_loss<min_test_loss:\n",
    "            print('Min loss changed from '+str(min_test_loss)+' to '+str(test_loss))\n",
    "            min_test_loss = test_loss\n",
    "            torch.save(model.state_dict(), model_name)\n",
    "        train_losses.append(train_loss)\n",
    "        test_losses.append(test_loss)\n",
    "        if epoch > 10 and min(test_losses[-7:])>min_test_loss+1e-9:\n",
    "            break\n",
    "        lr_scheduler.step(test_loss)\n",
    "        print('Epoch: ', str(epoch+1)+'/'+str(epochs),'| Training pTLoss: ', train_loss, '| Testing pTLoss: ', test_loss)\n",
    "        \n",
    "        if not prog_bar:\n",
    "            plt.plot(train_losses, label=\"Train Loss\")\n",
    "            plt.plot(test_losses, label=\"Validation Loss\")\n",
    "            plt.xlabel(\"# Epoch\")\n",
    "            plt.ylabel(\"Loss\")\n",
    "            plt.legend(loc='upper right')\n",
    "            plt.show()\n",
    "    return train_losses, test_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c4392942",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "var nb = IPython.notebook;\n",
       "var kernel = IPython.notebook.kernel;\n",
       "var command = \"NOTEBOOK_FULL_PATH = '\" + nb.base_url + nb.notebook_path + \"'\";\n",
       "kernel.execute(command);\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%javascript\n",
    "var nb = IPython.notebook;\n",
    "var kernel = IPython.notebook.kernel;\n",
    "var command = \"NOTEBOOK_FULL_PATH = '\" + nb.base_url + nb.notebook_path + \"'\";\n",
    "kernel.execute(command);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a77f1ea7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pTLoss: 0.0006609692: 100%|████████████████████████████████████████████████████████████| 58/58 [01:06<00:00,  1.15s/it]\n",
      "  0%|                                                                                           | 0/58 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min loss changed from inf to 0.0006709201727062463\n",
      "Epoch:  1/50 | Training pTLoss:  0.0008868348126396024 | Testing pTLoss:  0.0006709201727062463\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pTLoss: 0.0006590528: 100%|████████████████████████████████████████████████████████████| 58/58 [01:06<00:00,  1.14s/it]\n",
      "  0%|                                                                                           | 0/58 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min loss changed from 0.0006709201727062463 to 0.00066760186261187\n",
      "Epoch:  2/50 | Training pTLoss:  0.0006646697594109795 | Testing pTLoss:  0.00066760186261187\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pTLoss: 0.0006582409: 100%|████████████████████████████████████████████████████████████| 58/58 [01:07<00:00,  1.16s/it]\n",
      "  0%|                                                                                           | 0/58 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min loss changed from 0.00066760186261187 to 0.0006670340235965948\n",
      "Epoch:  3/50 | Training pTLoss:  0.0006631018828745159 | Testing pTLoss:  0.0006670340235965948\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pTLoss: 0.00065771025: 100%|███████████████████████████████████████████████████████████| 58/58 [01:07<00:00,  1.16s/it]\n",
      "  0%|                                                                                           | 0/58 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min loss changed from 0.0006670340235965948 to 0.0006667484024850031\n",
      "Epoch:  4/50 | Training pTLoss:  0.0006627972791742151 | Testing pTLoss:  0.0006667484024850031\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pTLoss: 0.0006574549: 100%|████████████████████████████████████████████████████████████| 58/58 [01:08<00:00,  1.19s/it]\n",
      "  0%|                                                                                           | 0/58 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min loss changed from 0.0006667484024850031 to 0.0006666060498294732\n",
      "Epoch:  5/50 | Training pTLoss:  0.000662640913325394 | Testing pTLoss:  0.0006666060498294732\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pTLoss: 0.0006572492: 100%|████████████████████████████████████████████████████████████| 58/58 [01:07<00:00,  1.16s/it]\n",
      "  0%|                                                                                           | 0/58 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min loss changed from 0.0006666060498294732 to 0.0006665095803327858\n",
      "Epoch:  6/50 | Training pTLoss:  0.0006625393018174661 | Testing pTLoss:  0.0006665095803327858\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pTLoss: 0.0006571214: 100%|████████████████████████████████████████████████████████████| 58/58 [01:07<00:00,  1.16s/it]\n",
      "  0%|                                                                                           | 0/58 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min loss changed from 0.0006665095803327858 to 0.000666448986157775\n",
      "Epoch:  7/50 | Training pTLoss:  0.0006624770166095476 | Testing pTLoss:  0.000666448986157775\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pTLoss: 0.0006570179: 100%|████████████████████████████████████████████████████████████| 58/58 [01:09<00:00,  1.20s/it]\n",
      "  0%|                                                                                           | 0/58 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min loss changed from 0.000666448986157775 to 0.000666400045156479\n",
      "Epoch:  8/50 | Training pTLoss:  0.0006624325620138956 | Testing pTLoss:  0.000666400045156479\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pTLoss: 0.0006569296: 100%|████████████████████████████████████████████████████████████| 58/58 [01:09<00:00,  1.21s/it]\n",
      "  0%|                                                                                           | 0/58 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min loss changed from 0.000666400045156479 to 0.0006663590436801314\n",
      "Epoch:  9/50 | Training pTLoss:  0.0006623988045813063 | Testing pTLoss:  0.0006663590436801314\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pTLoss: 0.00065685005: 100%|███████████████████████████████████████████████████████████| 58/58 [01:09<00:00,  1.19s/it]\n",
      "  0%|                                                                                           | 0/58 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min loss changed from 0.0006663590436801314 to 0.0006663228501565754\n",
      "Epoch:  10/50 | Training pTLoss:  0.0006623716055463743 | Testing pTLoss:  0.0006663228501565754\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pTLoss: 0.00065677514: 100%|███████████████████████████████████████████████████████████| 58/58 [01:09<00:00,  1.20s/it]\n",
      "  0%|                                                                                           | 0/58 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min loss changed from 0.0006663228501565754 to 0.0006662895049278935\n",
      "Epoch:  11/50 | Training pTLoss:  0.000662348470008322 | Testing pTLoss:  0.0006662895049278935\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pTLoss: 0.00065670017: 100%|███████████████████████████████████████████████████████████| 58/58 [01:09<00:00,  1.20s/it]\n",
      "  0%|                                                                                           | 0/58 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min loss changed from 0.0006662895049278935 to 0.0006662567689393956\n",
      "Epoch    12: reducing learning rate of group 0 to 5.0000e-04.\n",
      "Epoch:  12/50 | Training pTLoss:  0.0006623275313076788 | Testing pTLoss:  0.0006662567689393956\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pTLoss: 0.00065567397: 100%|███████████████████████████████████████████████████████████| 58/58 [01:09<00:00,  1.20s/it]\n",
      "  0%|                                                                                           | 0/58 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min loss changed from 0.0006662567689393956 to 0.0006658737314864993\n",
      "Epoch:  13/50 | Training pTLoss:  0.0006623404443761786 | Testing pTLoss:  0.0006658737314864993\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pTLoss: 0.0006556224: 100%|████████████████████████████████████████████████████████████| 58/58 [01:09<00:00,  1.20s/it]\n",
      "  0%|                                                                                           | 0/58 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min loss changed from 0.0006658737314864993 to 0.000665857852436602\n",
      "Epoch:  14/50 | Training pTLoss:  0.0006623446624244339 | Testing pTLoss:  0.000665857852436602\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pTLoss: 0.0006556075: 100%|████████████████████████████████████████████████████████████| 58/58 [01:09<00:00,  1.21s/it]\n",
      "  0%|                                                                                           | 0/58 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min loss changed from 0.000665857852436602 to 0.0006658531298550467\n",
      "Epoch    15: reducing learning rate of group 0 to 2.5000e-04.\n",
      "Epoch:  15/50 | Training pTLoss:  0.0006623347400254089 | Testing pTLoss:  0.0006658531298550467\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pTLoss: 0.0006551921: 100%|████████████████████████████████████████████████████████████| 58/58 [01:10<00:00,  1.21s/it]\n",
      "  0%|                                                                                           | 0/58 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min loss changed from 0.0006658531298550467 to 0.0006657243706285953\n",
      "Epoch:  16/50 | Training pTLoss:  0.0006623612024323568 | Testing pTLoss:  0.0006657243706285953\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pTLoss: 0.00065520586: 100%|███████████████████████████████████████████████████████████| 58/58 [01:11<00:00,  1.23s/it]\n",
      "  0%|                                                                                           | 0/58 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  17/50 | Training pTLoss:  0.0006623057706747206 | Testing pTLoss:  0.0006657274129490058\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pTLoss: 0.0006551906: 100%|████████████████████████████████████████████████████████████| 58/58 [01:11<00:00,  1.23s/it]\n",
      "  0%|                                                                                           | 0/58 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min loss changed from 0.0006657243706285953 to 0.0006657243085404237\n",
      "Epoch    18: reducing learning rate of group 0 to 1.2500e-04.\n",
      "Epoch:  18/50 | Training pTLoss:  0.0006623014422326254 | Testing pTLoss:  0.0006657243085404237\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pTLoss: 0.00065525697: 100%|███████████████████████████████████████████████████████████| 58/58 [01:11<00:00,  1.23s/it]\n",
      "  0%|                                                                                           | 0/58 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  19/50 | Training pTLoss:  0.0006622762222581639 | Testing pTLoss:  0.0006657335519169767\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pTLoss: 0.00065523916: 100%|███████████████████████████████████████████████████████████| 58/58 [01:10<00:00,  1.21s/it]\n",
      "  0%|                                                                                           | 0/58 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch    20: reducing learning rate of group 0 to 6.2500e-05.\n",
      "Epoch:  20/50 | Training pTLoss:  0.0006622698143975621 | Testing pTLoss:  0.0006657297102113564\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pTLoss: 0.000655291: 100%|█████████████████████████████████████████████████████████████| 58/58 [01:05<00:00,  1.13s/it]\n",
      "  0%|                                                                                           | 0/58 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  21/50 | Training pTLoss:  0.0006622423875498874 | Testing pTLoss:  0.0006657399353571237\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pTLoss: 0.0006552956: 100%|████████████████████████████████████████████████████████████| 58/58 [01:05<00:00,  1.13s/it]\n",
      "  0%|                                                                                           | 0/58 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch    22: reducing learning rate of group 0 to 3.1250e-05.\n",
      "Epoch:  22/50 | Training pTLoss:  0.000662250488450558 | Testing pTLoss:  0.0006657409830950202\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pTLoss: 0.00065531576: 100%|███████████████████████████████████████████████████████████| 58/58 [01:05<00:00,  1.13s/it]\n",
      "  0%|                                                                                           | 0/58 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  23/50 | Training pTLoss:  0.000662234347867619 | Testing pTLoss:  0.0006657450925558805\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pTLoss: 0.000655323: 100%|█████████████████████████████████████████████████████████████| 58/58 [01:05<00:00,  1.13s/it]\n",
      "  0%|                                                                                           | 0/58 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch    24: reducing learning rate of group 0 to 1.5625e-05.\n",
      "Epoch:  24/50 | Training pTLoss:  0.0006622393226154661 | Testing pTLoss:  0.0006657468271441757\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pTLoss: 0.0006553317: 100%|████████████████████████████████████████████████████████████| 58/58 [01:05<00:00,  1.13s/it]\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# device = torch.device('cpu')\n",
    "batch_size = 2**14\n",
    "epochs = 50\n",
    "model = MPNN().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=5e-4)\n",
    "# optimizer = torch.optim.Adam(model.parameters(), lr=0.002, weight_decay=5e-4)\n",
    "lr_scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, verbose=True, patience=1, factor=0.5)\n",
    "\n",
    "model_name = 'C:/Users/emrek/' + NOTEBOOK_FULL_PATH[:-6] + 'inv_' + str(inv) + '.pth'\n",
    "train_losses, test_losses = train(prog_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "751e1f8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0006657243085404237"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min(test_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8e717786",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_name = 'C:/Users/emrek/' + NOTEBOOK_FULL_PATH[:-6] + 'inv_' + str(inv) + '.pth'\n",
    "batch_size = 512\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "loaded_model = MPNN().to(device)\n",
    "rand_model = MPNN().to(device)\n",
    "optimizer = torch.optim.Adam(loaded_model.parameters(), lr=0.002, weight_decay=5e-4)\n",
    "loaded_model.load_state_dict(torch.load(model_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f35651c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 461/461 [00:20<00:00, 22.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test_loss: 0.0006655250057788194\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "test_loader = DataLoader(MyDataset(indices=test_mask), batch_size=batch_size)\n",
    "# test\n",
    "test_los = 0\n",
    "preds = []\n",
    "for data in tqdm(test_loader,position=0):\n",
    "    data = data.to(device)\n",
    "    optimizer.zero_grad()\n",
    "    out = loaded_model(data) # change rand_model to seee if it's trained - should not be the same loss\n",
    "    preds.append(out.cpu().detach())\n",
    "    labels = data.y\n",
    "    loss = pTLossTorch(out, data.y)\n",
    "    test_los += loss.cpu().detach().numpy()/len(test_loader)\n",
    "print('Test_loss: '+str(test_los))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ab2aea53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save to csv\n",
    "pred_ls = [float(i) for p in preds for i in p]\n",
    "len(pred_ls)\n",
    "df_pred = pd.DataFrame(pred_ls)\n",
    "df_pred.to_csv('C:/Users/emrek/' + NOTEBOOK_FULL_PATH[:-6] + ' inv_' + str(inv)+'.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b767bb22",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09f537dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# display(Javascript('IPython.notebook.execute_all_cells()'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acce612c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
